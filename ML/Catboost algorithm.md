каждый раз, когда создается дерево, данные перемешиваются и применяется [[CatboostEncoding]].

пороги для разделения датасета получаются путем кодировки категориальных переменных через [[CatboostEncoding]], замем их сортировки и нахождения градиентов с нижним соседом.

таргеты с неприрывным типом данных алгоритм распределяет по 'коробкам' (см. [[bins]]).

далее катбуст инициализирует нулём предикты ко всем рядам и считает остатки. 

по остаткам стоется дерево. изначально каждому листу присваевается значение 0. далее, по мере того, как таргеты сэмплов будут попадать в листья, базовое значение будет просто меняться на среднее, не считая изначального нуля.

по предиктам дерева и остаткам считается [[Cosine Similarity]], где А - остатки, а В - предикты дерева. 

Далее катбуст будет повторять вышенаписанное, пока не найдет дерево или ветку для дерева в наибольшим [[Cosine Similarity]]. 

когда лучшее дерево построено, к исходным предикат добавляют новые, умноженные не лернинг рейт. 

И так будет повторяться, пока не будет достаточно, как и у градиентного бустинга.

когда полученая модель будет предиктить значения, она будет кодировать их категориальные фичи так, будто они находятся внизу исходного датасета.

далее сэмплы будут проходить каждое дерево и получать предикты. Предикты будут суммироваться и умножаться на лернинг рейт. 

Катбуст стороит [[Oblivious Decision Trees]].


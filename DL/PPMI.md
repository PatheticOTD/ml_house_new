В отличие от [[tf-idf]], используется для [[term-term matrix]].

**Pointwise mutual information** - мера, определяющая частоту появления событий *x* и *y* совместно, нежели если бы они были независимы и появлялись поотдельности:
$$
I(x, y) = \log_2{\frac{P(x,y)}{P(x)P(y)}}
$$
В нлп место икса занимает целевое слово w, а вместо игрика - сонтекстное слово c. 

ПМИ выдает значения от -inf до +inf. Отрицательные значения могут быть ненадежными при маленьком корпусе. Поэтому отрицательные значения заменяют нулями:
$$
PPMI(w,c) = max(log_2{\frac{P(w,c)}{P(w)P(c)}}, 0)
$$
PMI предрасположен к редким событиям, очень редко пми выдает высокие значения словам. Способ, которым можно сместить эту предрасположенность - это изменить вычисление вероятности контекстного слова c:
$$
P_{\alpha(c)}= \frac{count(c)^\alpha}{\sum\limits_ccount(c)^\alpha}
$$
Рекомендованное значение альфы - 0.75.

FaceNet: A Unified Embedding for Face Recognition and Clustering.

![[Screenshot from 2024-10-01 17-38-00.png]]

архитектура нейронки не так важна, как следующие стадии. Нейронку можно взять любую. В оригинальной статье это была [[GoogLeNet]].

цель метода:
для пикчи $x$ получить ембединг $f(x)$ такой, что дистанция от одной такого ембединга до остальных такогоже класса минимально, а для разных классов максимально. Но это всё очевидности. 

### Triplet loss
![[Screenshot from 2024-10-01 17-46-38.png]]
Это оценка, которая высчитывает расстояние между "якорем" и двумя другими объектами разных классов, причем один из них имеет класс такойже как и у якоря.
![[Screenshot from 2024-10-01 18-00-11.png]]
В результате обучения якорь должен быть ближе к объектам своего класса на примерно $a$, чем к другим. 
Так как пространство тау ( это большая Т на картинке выше в формуле 2) это пространство всех возможных троек подобных элементов, то ради эффективности берут только самые важные триплеты следующим образом. 
### Triplet selection
Очень важно выбирать при обучении триплеты, которые будут нарушать (1), те брать триплеты, где негативный сэмпл находится как можно ближе к якорю, а позитивный как можно дальше. 
Это очень ресурсозатратно, к томуже может приводить к доминации изображений плохого качества и неправильным классом

Можно сделать следующее:
1) генерировать триплеты каждые n эпох (offline)
2) генерировать триплеты по минибатчам (online)

##### Online метод
Для него используют большие минибатчи в несколько тысяч. Для каждого лица должно быть одинаковое колличесто изображений. В работе брали по 40 картинок на лицо
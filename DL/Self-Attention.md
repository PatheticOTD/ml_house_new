Это более усложненная версия [[Attension]], которую называют еще attention head. 
Эта голова состоит из трех матриц:
1) query - текущий элемент сравнивается с прошлыми
2) key - прошлый элемент сравнивается с текущим для определения сходства
3) value -  предыдущий элемент сумируется с текущим для вычисления результата для текущего элемента. 
Эти матрицы будут обозначаться, как $W^Q,W^K,$  и $W^V$. эти веса будут проецировать каждый вектор инпутов $x_i$ в проекции: $$
q_{i}= x_iW^Q;k_{i}=x_iW^K;v_i=x_iW^V
$$
Когда мы считаем схожесть текущекго $x_i$ и предыдущего $x_j$, мы используем дот продукт между $q_i$ и $k_j$. Так как результат вычислений будет очень большим, мы делим его на корень размености $d_k$ . 
Вот полный список формул:
![[Pasted image 20250118123333.png]]
![[Pasted image 20250118123359.png]]
